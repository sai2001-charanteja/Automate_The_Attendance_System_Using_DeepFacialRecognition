{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7n109-gfKsJ",
        "outputId": "29f1959e-8299-4294-92a2-0e87283bc0f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "feAfj-5Gib9J",
        "outputId": "3f759d80-40c9-47fc-b66d-d6e229c47bbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1-7XeLp7el2PwfO1ASYbDd4MwTAeC52oX/Face_Recognition\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/My Drive/Colab Notebooks/Face_Recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "a9oEs4j1ivxk"
      },
      "outputs": [],
      "source": [
        "path='/content/drive/My Drive/Colab Notebooks/Face_Recognition'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtlDLsfXdbQS",
        "outputId": "962064ca-2b6c-4dc3-857a-f1f976ff246c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (4.6.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.12.2)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.27.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.65.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.4.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Collecting twilio\n",
            "  Downloading twilio-8.5.0-py2.py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from twilio) (2022.7.1)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from twilio) (2.27.1)\n",
            "Collecting PyJWT<3.0.0,>=2.0.0 (from twilio)\n",
            "  Downloading PyJWT-2.7.0-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: aiohttp>=3.8.4 in /usr/local/lib/python3.10/dist-packages (from twilio) (3.8.4)\n",
            "Collecting aiohttp-retry>=2.8.3 (from twilio)\n",
            "  Downloading aiohttp_retry-2.8.3-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->twilio) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->twilio) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->twilio) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->twilio) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->twilio) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->twilio) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->twilio) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->twilio) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->twilio) (2023.5.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->twilio) (3.4)\n",
            "Installing collected packages: PyJWT, aiohttp-retry, twilio\n",
            "Successfully installed PyJWT-2.7.0 aiohttp-retry-2.8.3 twilio-8.5.0\n",
            "Collecting redmail\n",
            "  Downloading redmail-0.6.0-py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.9/46.9 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from redmail) (3.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->redmail) (2.1.3)\n",
            "Installing collected packages: redmail\n",
            "Successfully installed redmail-0.6.0\n"
          ]
        }
      ],
      "source": [
        "! pip install gdown\n",
        "\n",
        "!pip install twilio\n",
        "!pip install redmail"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8WTJ__FHi4mY"
      },
      "outputs": [],
      "source": [
        "# Libraries used\n",
        "\n",
        "# Usual Libraries\n",
        "import os\n",
        "import re\n",
        "import glob\n",
        "from google.colab.patches import cv2_imshow\n",
        "from datetime import datetime\n",
        "\n",
        "# For Face Detection\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import dlib\n",
        "\n",
        "# Tensorflow Library Mainly for keras\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential,Model\n",
        "from tensorflow.keras.layers import ZeroPadding2D,Convolution2D,MaxPooling2D\n",
        "from tensorflow.keras.layers import Dense,Dropout,Softmax,Flatten,Activation,BatchNormalization\n",
        "from tensorflow.keras.preprocessing.image import load_img,img_to_array\n",
        "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "# Threading for making the testing faster\n",
        "import threading\n",
        "from collections import defaultdict\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# For Sending the attendance Information through Mass Media like Whatsapp and Gmail.\n",
        "\n",
        "#For Whatsapp\n",
        "from twilio.rest import Client\n",
        "\n",
        "#For Gmail\n",
        "from redmail import outlook\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "JbYplJagkWc2"
      },
      "outputs": [],
      "source": [
        "# Get Image names stored in \"Images\" folder\n",
        "image_path_names=[]\n",
        "person_names=set()\n",
        "for file_name in glob.glob(path+'/Images/*[1-9]*.jpg'):\n",
        "  image_path_names.append(file_name)\n",
        "  person_names.add(re.sub(r'[0-9]', '', image_path_names[-1].split('/')[-1].split('.')[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0VQO0oRkoKe",
        "outputId": "e24953b6-dbcd-4bb0-e088-852ea57c96d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Number of students faces are 78\n"
          ]
        }
      ],
      "source": [
        "#Total Number of Student Name\n",
        "print(\"Total Number of students faces are {0}\".format(len(image_path_names)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzJua7rHll-Q",
        "outputId": "8471e509-a2e0-4c76-c837-5ed2942ecf1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All Student names {'MalliReddy', 'Pragna', 'RamCharanTeja', 'Ranjith', 'NTR', 'Shiva', 'saiCharanTeja', 'Pragna ()'}\n"
          ]
        }
      ],
      "source": [
        "# All the names of Students\n",
        "print(\"All Student names\",person_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrvHS5nkO0VX"
      },
      "source": [
        "  There are total 70 images containing 10 images per person."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDEOeTvSn09H",
        "outputId": "4f1d0391-52c3-416f-84e4-f6e6ae4bdc3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-14 15:57:26--  http://dlib.net/files/mmod_human_face_detector.dat.bz2\n",
            "Resolving dlib.net (dlib.net)... 107.180.26.78\n",
            "Connecting to dlib.net (dlib.net)|107.180.26.78|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 694709 (678K)\n",
            "Saving to: ‘mmod_human_face_detector.dat.bz2’\n",
            "\n",
            "mmod_human_face_det 100%[===================>] 678.43K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2023-07-14 15:57:26 (5.37 MB/s) - ‘mmod_human_face_detector.dat.bz2’ saved [694709/694709]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Download Dlib CNN face detector\n",
        "! wget http://dlib.net/files/mmod_human_face_detector.dat.bz2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ntLNPejsPU8",
        "outputId": "8cf1aeb7-191b-4fb3-c6b2-6892d33fa8b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bzip2: Output file mmod_human_face_detector.dat already exists.\n"
          ]
        }
      ],
      "source": [
        "!bzip2 -dk mmod_human_face_detector.dat.bz2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ugCOCE_lsTlP"
      },
      "outputs": [],
      "source": [
        "%rm mmod_human_face_detector.dat.bz2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Vdo0aJNkA_sy"
      },
      "outputs": [],
      "source": [
        "# Load CNN face detector into dlib\n",
        "dnnFaceDetector=dlib.cnn_face_detection_model_v1(\"mmod_human_face_detector.dat\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "21_IVMOgybPU"
      },
      "outputs": [],
      "source": [
        "# Create a Folder Image_Crop\n",
        "if(os.path.exists(path+'/Images_crop/')== False):\n",
        "    os.mkdir(path+'/Images_crop/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "UvnDaqCDIqmL"
      },
      "outputs": [],
      "source": [
        "# For each person create a separate folder\n",
        "for person in person_names:\n",
        "    if(os.path.exists(path+'/Images_crop/'+person+'/') == False):\n",
        "        os.mkdir(path+'/Images_crop/'+person+'/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "UjJsN13m8Hen"
      },
      "outputs": [],
      "source": [
        "def Crop_Detected_Faces(file_name,img_path):\n",
        "    img=cv2.imread(file_name)\n",
        "    gray=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    rects=dnnFaceDetector(gray,1)\n",
        "\n",
        "    left,top,right,bottom=0,0,0,0\n",
        "    for (i,rect) in enumerate(rects):\n",
        "        left=rect.rect.left() #x1\n",
        "        top=rect.rect.top() #y1\n",
        "        right=rect.rect.right() #x2\n",
        "        bottom=rect.rect.bottom() #y2\n",
        "    width=right-left\n",
        "    height=bottom-top\n",
        "    img_crop=img[abs(top):abs(top)+height,abs(left):abs(left)+width]\n",
        "\n",
        "    cv2.imwrite(img_path,img_crop)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "aRf_JMqu7y50"
      },
      "outputs": [],
      "source": [
        "# Detect face, crop detected face and save them in corresponding person folder\n",
        "threads = []\n",
        "for file_name in image_path_names:\n",
        "    img_path=path+'/Images_crop/'+re.sub(r'[0-9]', '', file_name.split('/')[-1].split('.')[0])+\"/\"+file_name.split('/')[-1]\n",
        "    t = threading.Thread(target=Crop_Detected_Faces, args=(file_name,img_path,))\n",
        "\n",
        "    threads.append(t)\n",
        "    t.start()\n",
        "\n",
        "# Wait for all threads to finish\n",
        "for t in threads:\n",
        "    t.join()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "q0B5EsUzQIIZ"
      },
      "outputs": [],
      "source": [
        "# Get Image names for testing\n",
        "test_image_path_names=[]\n",
        "for file_name in glob.glob(path+'/Images_test/*_[123].jpg'):\n",
        "  test_image_path_names.append(file_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhLxtZuDRD-3",
        "outputId": "6de9f963-e1fa-408d-cd41-1b5574c4edfb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of student test images 21\n"
          ]
        }
      ],
      "source": [
        "print(\"Total number of student test images {0}\".format(len(test_image_path_names)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4g5jL7iRWdh"
      },
      "source": [
        "For each person 3 images to test in Images_test folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "uXjqG2ZnRFTD"
      },
      "outputs": [],
      "source": [
        "# Creating a Test Images Crop folder\n",
        "if(os.path.exists(path+'/Images_Test_crop/') == False):\n",
        "    os.mkdir(path+'/Images_Test_crop/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ff0ekPxwRwWG"
      },
      "outputs": [],
      "source": [
        "# Create Separate folder for each person in \"Test_Images_crop\" folder\n",
        "for person in person_names:\n",
        "    if(os.path.exists(path+'/Images_Test_crop/'+person+'/') == False):\n",
        "        os.mkdir(path+'/Images_Test_crop/'+person+'/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "GknhH1cv_q2l"
      },
      "outputs": [],
      "source": [
        "# Detect face,crop face and save in corresponding folder\n",
        "threads = []\n",
        "for file_name in test_image_path_names:\n",
        "    img_path=path+'/Images_Test_crop/'+file_name.split('/')[-1].split('_')[0]+'/'+file_name.split('/')[-1]\n",
        "    t = threading.Thread(target=Crop_Detected_Faces, args=(file_name,img_path))\n",
        "    threads.append(t)\n",
        "    t.start()\n",
        "\n",
        "# Wait for all threads to finish\n",
        "for t in threads:\n",
        "    t.join()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSmSIDhoPNM7"
      },
      "source": [
        "<pre>Here images are sorted to corresponding test and train folders of same person\n",
        "Directory structure :\n",
        "|Images /\n",
        "|  |-- (60 images) - Images of student. 10 Images of each student.\n",
        "|Images_crop /\n",
        "|  |--SaiCharanTeja /\n",
        "|     |--(10 images)\n",
        "|  |--Pargna /\n",
        "|     |--(10 images)\n",
        "|  |--MalliReddy /\n",
        "|         |--(10 imgaes)\n",
        "|  |--Pranay /\n",
        "|         |--(10 imgaes)\n",
        "|Images_test / - Given Images to test the model.Each of 3 Images\n",
        "|  |-- .. / (18 images)\n",
        "|Images_test_crop /\n",
        "|  |--SaiCharanTeja / (3 images)\n",
        "|  |--Pargna / (3 images)\n",
        "|  |--MalliReddy / (3 images)\n",
        "|  |--Pranay / (3 images)\n",
        "|Test_Images / - Images  to be tested.\n",
        "|  |-- There is no specified Number of Images.\n",
        "|  |--Predictions / - The predicted Images are stored with in this folder.\n",
        "|  |--Attendance/ - To store the daily attendance\n",
        "|vgg_face_weights.h5\n",
        "|train_data.npy\n",
        "|train_labels.npy\n",
        "|test_data.npy\n",
        "|test_labels.npy\n",
        "|Face_Recognition.ipynb\n",
        "|mmod_human_face_detector.dat\n",
        "|face_classifier_model.h5\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qF0i2mrxBTR0",
        "outputId": "3bf73b8d-6401-4c0d-b163-19eece9f0596"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "face_classifier_model.h5      \u001b[0m\u001b[01;34mPredictions\u001b[0m/        test_labels.npy\n",
            "\u001b[01;34mImages\u001b[0m/                       \u001b[01;34mStudentAttendance\u001b[0m/  train_data.npy\n",
            "\u001b[01;34mImages_crop\u001b[0m/                  Students_Info.xlsx  train_labels.npy\n",
            "\u001b[01;34mImages_test\u001b[0m/                  test_data.npy       vgg-face-keras-fc.h5\n",
            "\u001b[01;34mImages_Test_crop\u001b[0m/             \u001b[01;34mTest_Images\u001b[0m/        vgg_face_weights.h5\n",
            "mmod_human_face_detector.dat  \u001b[01;34mTest_Images_crop\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "%ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "x4_j4qVk_Pze"
      },
      "outputs": [],
      "source": [
        "#Define VGG_FACE_MODEL architecture\n",
        "model = Sequential()\n",
        "model.add(ZeroPadding2D((1,1),input_shape=(224,224, 3)))\n",
        "model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
        "model.add(Convolution2D(4096, (7, 7), activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Convolution2D(4096, (1, 1), activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Convolution2D(2622, (1, 1)))\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "hQV4WAcvANH0"
      },
      "outputs": [],
      "source": [
        "# Load VGG Face model weights\n",
        "model.load_weights(path+'/vgg_face_weights.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7k9g_wtCUfD",
        "outputId": "6bf8b84a-a338-492f-c0da-2b0d05584d6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " zero_padding2d (ZeroPadding  (None, 226, 226, 3)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " zero_padding2d_1 (ZeroPaddi  (None, 226, 226, 64)     0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 112, 112, 64)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " zero_padding2d_2 (ZeroPaddi  (None, 114, 114, 64)     0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " zero_padding2d_3 (ZeroPaddi  (None, 114, 114, 128)    0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 56, 56, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " zero_padding2d_4 (ZeroPaddi  (None, 58, 58, 128)      0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " zero_padding2d_5 (ZeroPaddi  (None, 58, 58, 256)      0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " zero_padding2d_6 (ZeroPaddi  (None, 58, 58, 256)      0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 28, 28, 256)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " zero_padding2d_7 (ZeroPaddi  (None, 30, 30, 256)      0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " zero_padding2d_8 (ZeroPaddi  (None, 30, 30, 512)      0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " zero_padding2d_9 (ZeroPaddi  (None, 30, 30, 512)      0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 14, 14, 512)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " zero_padding2d_10 (ZeroPadd  (None, 16, 16, 512)      0         \n",
            " ing2D)                                                          \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " zero_padding2d_11 (ZeroPadd  (None, 16, 16, 512)      0         \n",
            " ing2D)                                                          \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " zero_padding2d_12 (ZeroPadd  (None, 16, 16, 512)      0         \n",
            " ing2D)                                                          \n",
            "                                                                 \n",
            " conv2d_12 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 7, 7, 512)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, 1, 1, 4096)        102764544 \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1, 1, 4096)        0         \n",
            "                                                                 \n",
            " conv2d_14 (Conv2D)          (None, 1, 1, 4096)        16781312  \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 1, 1, 4096)        0         \n",
            "                                                                 \n",
            " conv2d_15 (Conv2D)          (None, 1, 1, 2622)        10742334  \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2622)              0         \n",
            "                                                                 \n",
            " activation (Activation)     (None, 2622)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 145,002,878\n",
            "Trainable params: 145,002,878\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "nZ21pD4FDLkT"
      },
      "outputs": [],
      "source": [
        "# Remove Last Softmax layer and get model upto last flatten layer with outputs 2622 units\n",
        "vgg_face=Model(inputs=model.layers[0].input,outputs=model.layers[-2].output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "6zSqFno_Epfz"
      },
      "outputs": [],
      "source": [
        "#Prepare Training Data\n",
        "x_train=[]\n",
        "y_train=[]\n",
        "person_folders=os.listdir(path+'/Images_crop/')\n",
        "\n",
        "person_rep=dict()\n",
        "for i,person in enumerate(person_folders):\n",
        "  person_rep[i]=person\n",
        "  image_names=os.listdir('Images_crop/'+person+'/')\n",
        "  for image_name in image_names:\n",
        "    img=load_img(path+'/Images_crop/'+person+'/'+image_name,target_size=(224,224))\n",
        "    img=img_to_array(img)\n",
        "    img=np.expand_dims(img,axis=0)\n",
        "    img=preprocess_input(img)\n",
        "    img_encode=vgg_face(img)\n",
        "    x_train.append(np.squeeze(K.eval(img_encode)).tolist())\n",
        "    y_train.append(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Cl8ewCNRRCu",
        "outputId": "172e68b8-cc59-4287-f638-77c301ff8191"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'Shiva',\n",
              " 1: 'RamCharanTeja',\n",
              " 2: 'saiCharanTeja',\n",
              " 3: 'Ranjith',\n",
              " 4: 'NTR',\n",
              " 5: 'Pragna ()',\n",
              " 6: 'MalliReddy',\n",
              " 7: 'Pragna'}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "person_rep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "QyxgU05lSX4D"
      },
      "outputs": [],
      "source": [
        "x_train=np.array(x_train)\n",
        "y_train=np.array(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "aylVlQO2SZXB"
      },
      "outputs": [],
      "source": [
        "#Prepare Test Data\n",
        "x_test=[]\n",
        "y_test=[]\n",
        "person_folders=os.listdir(path+'/Images_Test_crop/')\n",
        "for i,person in enumerate(person_folders):\n",
        "  image_names=os.listdir('Images_Test_crop/'+person+'/')\n",
        "  for image_name in image_names:\n",
        "    img=load_img(path+'/Images_Test_crop/'+person+'/'+image_name,target_size=(224,224))\n",
        "    img=img_to_array(img)\n",
        "    img=np.expand_dims(img,axis=0)\n",
        "\n",
        "    img=preprocess_input(img)\n",
        "    img_encode=vgg_face(img)\n",
        "\n",
        "    x_test.append(np.squeeze(K.eval(img_encode)).tolist())\n",
        "    y_test.append(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "C4NNw5lqTuKL"
      },
      "outputs": [],
      "source": [
        "x_test=np.array(x_test)\n",
        "y_test=np.array(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "EAT3ehPVT-24"
      },
      "outputs": [],
      "source": [
        "# Save test and train data for later use\n",
        "np.save('train_data',x_train)\n",
        "np.save('train_labels',y_train)\n",
        "np.save('test_data',x_test)\n",
        "np.save('test_labels',y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "sQ5aWACqUnX3"
      },
      "outputs": [],
      "source": [
        "# Load saved data\n",
        "x_train=np.load('train_data.npy')\n",
        "y_train=np.load('train_labels.npy')\n",
        "x_test=np.load('test_data.npy')\n",
        "y_test=np.load('test_labels.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "wZOEaNOb0qxD"
      },
      "outputs": [],
      "source": [
        "# Softmax regressor to classify images based on encoding\n",
        "classifier_model=Sequential()\n",
        "\n",
        "classifier_model.add(Dense(units=100,input_dim=x_train.shape[1],kernel_initializer='glorot_uniform'))\n",
        "classifier_model.add(BatchNormalization())\n",
        "classifier_model.add(Activation('tanh'))\n",
        "classifier_model.add(Dropout(0.3))\n",
        "\n",
        "classifier_model.add(Dense(units=10,kernel_initializer='glorot_uniform'))\n",
        "classifier_model.add(BatchNormalization())\n",
        "classifier_model.add(Activation('tanh'))\n",
        "classifier_model.add(Dropout(0.2))\n",
        "\n",
        "classifier_model.add(Dense(units=8,kernel_initializer='he_uniform'))\n",
        "classifier_model.add(Activation('softmax'))\n",
        "classifier_model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits= True),optimizer='nadam',metrics=['accuracy'])\n",
        "#classifier_model.compile(loss=tf.keras.losses.binary_crossentropy(),optimizer='Adam',metrics=['accuracy'])\n",
        "# classifier_model.compile(loss=\"sparse_categorical_crossentropy\",optimizer='Nadam',metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNJsffbD4ulB",
        "outputId": "70cf8235-79b5-448b-8d07-d078d59fbd45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/backend.py:5612: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 4s 117ms/step - loss: 1.9997 - accuracy: 0.2179 - val_loss: 3.0708 - val_accuracy: 0.0476\n",
            "Epoch 2/250\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.9403 - accuracy: 0.7564 - val_loss: 3.2728 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/250\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.7714 - accuracy: 0.8590 - val_loss: 3.3401 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/250\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.5858 - accuracy: 0.9744 - val_loss: 3.3153 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/250\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.6131 - accuracy: 0.9615 - val_loss: 3.3905 - val_accuracy: 0.0952\n",
            "Epoch 6/250\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.5992 - accuracy: 0.9615 - val_loss: 3.3500 - val_accuracy: 0.0476\n",
            "Epoch 7/250\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.5223 - accuracy: 0.9487 - val_loss: 3.3021 - val_accuracy: 0.0952\n",
            "Epoch 8/250\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.5200 - accuracy: 0.9744 - val_loss: 3.2814 - val_accuracy: 0.0952\n",
            "Epoch 9/250\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.4451 - accuracy: 1.0000 - val_loss: 3.2934 - val_accuracy: 0.0952\n",
            "Epoch 10/250\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.4824 - accuracy: 0.9872 - val_loss: 3.3145 - val_accuracy: 0.0476\n",
            "Epoch 11/250\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.5383 - accuracy: 0.9872 - val_loss: 3.3095 - val_accuracy: 0.0476\n",
            "Epoch 12/250\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.4438 - accuracy: 1.0000 - val_loss: 3.3184 - val_accuracy: 0.0476\n",
            "Epoch 13/250\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.4631 - accuracy: 0.9744 - val_loss: 3.3596 - val_accuracy: 0.0952\n",
            "Epoch 14/250\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.4467 - accuracy: 0.9615 - val_loss: 3.3898 - val_accuracy: 0.0952\n",
            "Epoch 15/250\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.4022 - accuracy: 0.9872 - val_loss: 3.3933 - val_accuracy: 0.0952\n",
            "Epoch 16/250\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.4713 - accuracy: 0.9744 - val_loss: 3.3812 - val_accuracy: 0.0952\n",
            "Epoch 17/250\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.3832 - accuracy: 0.9872 - val_loss: 3.3759 - val_accuracy: 0.0952\n",
            "Epoch 18/250\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.3784 - accuracy: 1.0000 - val_loss: 3.3770 - val_accuracy: 0.0952\n",
            "Epoch 19/250\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.3684 - accuracy: 1.0000 - val_loss: 3.3843 - val_accuracy: 0.0952\n",
            "Epoch 20/250\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.3566 - accuracy: 1.0000 - val_loss: 3.3980 - val_accuracy: 0.0952\n",
            "Epoch 21/250\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.4553 - accuracy: 1.0000 - val_loss: 3.4474 - val_accuracy: 0.0952\n",
            "Epoch 22/250\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.3509 - accuracy: 1.0000 - val_loss: 3.4675 - val_accuracy: 0.0952\n",
            "Epoch 23/250\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.3659 - accuracy: 0.9872 - val_loss: 3.4671 - val_accuracy: 0.0952\n",
            "Epoch 24/250\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.3766 - accuracy: 0.9872 - val_loss: 3.4492 - val_accuracy: 0.0952\n",
            "Epoch 25/250\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.3665 - accuracy: 0.9744 - val_loss: 3.4621 - val_accuracy: 0.0952\n",
            "Epoch 26/250\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.3900 - accuracy: 0.9872 - val_loss: 3.4821 - val_accuracy: 0.0952\n",
            "Epoch 27/250\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.3171 - accuracy: 1.0000 - val_loss: 3.4876 - val_accuracy: 0.0952\n",
            "Epoch 28/250\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.3102 - accuracy: 1.0000 - val_loss: 3.4678 - val_accuracy: 0.0952\n",
            "Epoch 29/250\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 0.3726 - accuracy: 0.9872 - val_loss: 3.4573 - val_accuracy: 0.0952\n",
            "Epoch 30/250\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 0.3334 - accuracy: 1.0000 - val_loss: 3.4631 - val_accuracy: 0.0952\n",
            "Epoch 31/250\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 0.2900 - accuracy: 1.0000 - val_loss: 3.4846 - val_accuracy: 0.0952\n",
            "Epoch 32/250\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 0.3208 - accuracy: 1.0000 - val_loss: 3.4857 - val_accuracy: 0.0952\n",
            "Epoch 33/250\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.3549 - accuracy: 1.0000 - val_loss: 3.4709 - val_accuracy: 0.0952\n",
            "Epoch 34/250\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.2974 - accuracy: 0.9872 - val_loss: 3.4718 - val_accuracy: 0.0952\n",
            "Epoch 35/250\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.3283 - accuracy: 0.9872 - val_loss: 3.4840 - val_accuracy: 0.0952\n",
            "Epoch 36/250\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.3272 - accuracy: 1.0000 - val_loss: 3.5025 - val_accuracy: 0.0952\n",
            "Epoch 37/250\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.3093 - accuracy: 1.0000 - val_loss: 3.5212 - val_accuracy: 0.0952\n",
            "Epoch 38/250\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.3156 - accuracy: 1.0000 - val_loss: 3.5428 - val_accuracy: 0.1429\n",
            "Epoch 39/250\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.3084 - accuracy: 1.0000 - val_loss: 3.5488 - val_accuracy: 0.1429\n",
            "Epoch 40/250\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.3144 - accuracy: 1.0000 - val_loss: 3.5470 - val_accuracy: 0.1429\n",
            "Epoch 41/250\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.2615 - accuracy: 1.0000 - val_loss: 3.5386 - val_accuracy: 0.1429\n",
            "Epoch 42/250\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.2698 - accuracy: 1.0000 - val_loss: 3.5588 - val_accuracy: 0.1429\n",
            "Epoch 43/250\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.2942 - accuracy: 1.0000 - val_loss: 3.5992 - val_accuracy: 0.1429\n",
            "Epoch 44/250\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.2762 - accuracy: 1.0000 - val_loss: 3.6219 - val_accuracy: 0.1429\n",
            "Epoch 45/250\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.2873 - accuracy: 1.0000 - val_loss: 3.6559 - val_accuracy: 0.1429\n",
            "Epoch 46/250\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.3057 - accuracy: 1.0000 - val_loss: 3.6787 - val_accuracy: 0.1429\n",
            "Epoch 47/250\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.2419 - accuracy: 0.9872 - val_loss: 3.6901 - val_accuracy: 0.1429\n",
            "Epoch 48/250\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.2681 - accuracy: 0.9872 - val_loss: 3.6948 - val_accuracy: 0.1429\n",
            "Epoch 49/250\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 0.2735 - accuracy: 1.0000 - val_loss: 3.7042 - val_accuracy: 0.1429\n",
            "Epoch 50/250\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.2290 - accuracy: 1.0000 - val_loss: 3.7082 - val_accuracy: 0.1429\n",
            "Epoch 51/250\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.2093 - accuracy: 1.0000 - val_loss: 3.7284 - val_accuracy: 0.1429\n",
            "Epoch 52/250\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.2474 - accuracy: 1.0000 - val_loss: 3.7440 - val_accuracy: 0.1429\n",
            "Epoch 53/250\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.2608 - accuracy: 1.0000 - val_loss: 3.7420 - val_accuracy: 0.1429\n",
            "Epoch 54/250\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.2493 - accuracy: 1.0000 - val_loss: 3.7288 - val_accuracy: 0.1429\n",
            "Epoch 55/250\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.2350 - accuracy: 1.0000 - val_loss: 3.7308 - val_accuracy: 0.1429\n",
            "Epoch 56/250\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.2444 - accuracy: 1.0000 - val_loss: 3.7095 - val_accuracy: 0.1429\n",
            "Epoch 57/250\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.2697 - accuracy: 1.0000 - val_loss: 3.6836 - val_accuracy: 0.1429\n",
            "Epoch 58/250\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.2353 - accuracy: 0.9872 - val_loss: 3.6693 - val_accuracy: 0.1429\n",
            "Epoch 59/250\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.2613 - accuracy: 1.0000 - val_loss: 3.6718 - val_accuracy: 0.1429\n",
            "Epoch 60/250\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.2559 - accuracy: 1.0000 - val_loss: 3.6616 - val_accuracy: 0.1429\n",
            "Epoch 61/250\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.2168 - accuracy: 1.0000 - val_loss: 3.6671 - val_accuracy: 0.1429\n",
            "Epoch 62/250\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.1981 - accuracy: 1.0000 - val_loss: 3.6857 - val_accuracy: 0.1429\n",
            "Epoch 63/250\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.2468 - accuracy: 1.0000 - val_loss: 3.6962 - val_accuracy: 0.1429\n",
            "Epoch 64/250\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.2549 - accuracy: 1.0000 - val_loss: 3.7208 - val_accuracy: 0.1429\n",
            "Epoch 65/250\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.2371 - accuracy: 1.0000 - val_loss: 3.7464 - val_accuracy: 0.1429\n",
            "Epoch 66/250\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.2272 - accuracy: 1.0000 - val_loss: 3.7499 - val_accuracy: 0.1429\n",
            "Epoch 67/250\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.2381 - accuracy: 0.9872 - val_loss: 3.7486 - val_accuracy: 0.1429\n",
            "Epoch 68/250\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.2091 - accuracy: 1.0000 - val_loss: 3.7397 - val_accuracy: 0.1429\n",
            "Epoch 69/250\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.1899 - accuracy: 1.0000 - val_loss: 3.7229 - val_accuracy: 0.1429\n",
            "Epoch 70/250\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.1813 - accuracy: 1.0000 - val_loss: 3.7346 - val_accuracy: 0.1429\n",
            "Epoch 71/250\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.2126 - accuracy: 1.0000 - val_loss: 3.7536 - val_accuracy: 0.1429\n",
            "Epoch 72/250\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.2135 - accuracy: 1.0000 - val_loss: 3.7624 - val_accuracy: 0.1429\n",
            "Epoch 73/250\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.1805 - accuracy: 1.0000 - val_loss: 3.7667 - val_accuracy: 0.1429\n",
            "Epoch 74/250\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.1931 - accuracy: 1.0000 - val_loss: 3.7617 - val_accuracy: 0.1429\n",
            "Epoch 75/250\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.2025 - accuracy: 1.0000 - val_loss: 3.7759 - val_accuracy: 0.1429\n",
            "Epoch 76/250\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.2322 - accuracy: 1.0000 - val_loss: 3.7988 - val_accuracy: 0.1429\n",
            "Epoch 77/250\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.2163 - accuracy: 1.0000 - val_loss: 3.8402 - val_accuracy: 0.1429\n",
            "Epoch 78/250\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.1997 - accuracy: 1.0000 - val_loss: 3.8782 - val_accuracy: 0.1429\n",
            "Epoch 79/250\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.1937 - accuracy: 1.0000 - val_loss: 3.9010 - val_accuracy: 0.1429\n",
            "Epoch 80/250\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.1948 - accuracy: 1.0000 - val_loss: 3.9045 - val_accuracy: 0.1429\n",
            "Epoch 81/250\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.1903 - accuracy: 1.0000 - val_loss: 3.9053 - val_accuracy: 0.1429\n",
            "Epoch 82/250\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.2024 - accuracy: 1.0000 - val_loss: 3.9308 - val_accuracy: 0.1429\n",
            "Epoch 83/250\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.1788 - accuracy: 1.0000 - val_loss: 3.9237 - val_accuracy: 0.1429\n",
            "Epoch 84/250\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.2155 - accuracy: 1.0000 - val_loss: 3.8883 - val_accuracy: 0.1429\n",
            "Epoch 85/250\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.1579 - accuracy: 1.0000 - val_loss: 3.8602 - val_accuracy: 0.1429\n",
            "Epoch 86/250\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.1819 - accuracy: 1.0000 - val_loss: 3.8282 - val_accuracy: 0.1429\n",
            "Epoch 87/250\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.2151 - accuracy: 1.0000 - val_loss: 3.8407 - val_accuracy: 0.1429\n",
            "Epoch 88/250\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.1855 - accuracy: 1.0000 - val_loss: 3.8513 - val_accuracy: 0.1429\n",
            "Epoch 89/250\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.1988 - accuracy: 1.0000 - val_loss: 3.8874 - val_accuracy: 0.1429\n",
            "Epoch 90/250\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.1761 - accuracy: 1.0000 - val_loss: 3.9487 - val_accuracy: 0.1429\n",
            "Epoch 91/250\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.1707 - accuracy: 1.0000 - val_loss: 3.9843 - val_accuracy: 0.1429\n",
            "Epoch 92/250\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.1829 - accuracy: 0.9872 - val_loss: 4.0157 - val_accuracy: 0.1429\n",
            "Epoch 93/250\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.1537 - accuracy: 1.0000 - val_loss: 4.0147 - val_accuracy: 0.1429\n",
            "Epoch 94/250\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 0.1562 - accuracy: 1.0000 - val_loss: 4.0022 - val_accuracy: 0.1429\n",
            "Epoch 95/250\n",
            "3/3 [==============================] - 0s 48ms/step - loss: 0.1588 - accuracy: 0.9872 - val_loss: 4.0013 - val_accuracy: 0.1429\n",
            "Epoch 96/250\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.1644 - accuracy: 1.0000 - val_loss: 4.0251 - val_accuracy: 0.1429\n",
            "Epoch 97/250\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.1711 - accuracy: 0.9872 - val_loss: 4.0448 - val_accuracy: 0.1429\n",
            "Epoch 98/250\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 0.1392 - accuracy: 0.9872 - val_loss: 4.0601 - val_accuracy: 0.1429\n",
            "Epoch 99/250\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 0.1313 - accuracy: 1.0000 - val_loss: 4.0543 - val_accuracy: 0.1429\n",
            "Epoch 100/250\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.1604 - accuracy: 1.0000 - val_loss: 4.0421 - val_accuracy: 0.1429\n",
            "Epoch 101/250\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.1363 - accuracy: 1.0000 - val_loss: 4.0275 - val_accuracy: 0.1429\n",
            "Epoch 102/250\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.1887 - accuracy: 1.0000 - val_loss: 3.9987 - val_accuracy: 0.1429\n",
            "Epoch 103/250\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 0.1571 - accuracy: 1.0000 - val_loss: 3.9877 - val_accuracy: 0.1429\n",
            "Epoch 104/250\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.1322 - accuracy: 1.0000 - val_loss: 3.9849 - val_accuracy: 0.1429\n",
            "Epoch 105/250\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.1473 - accuracy: 1.0000 - val_loss: 4.0368 - val_accuracy: 0.1429\n",
            "Epoch 106/250\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.1343 - accuracy: 1.0000 - val_loss: 4.0871 - val_accuracy: 0.1429\n",
            "Epoch 107/250\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.1355 - accuracy: 1.0000 - val_loss: 4.1029 - val_accuracy: 0.1429\n",
            "Epoch 108/250\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.1297 - accuracy: 1.0000 - val_loss: 4.0980 - val_accuracy: 0.1429\n",
            "Epoch 109/250\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 0.1376 - accuracy: 0.9872 - val_loss: 4.1070 - val_accuracy: 0.1429\n",
            "Epoch 110/250\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 0.1623 - accuracy: 1.0000 - val_loss: 4.1171 - val_accuracy: 0.1429\n",
            "Epoch 111/250\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 0.1308 - accuracy: 1.0000 - val_loss: 4.1265 - val_accuracy: 0.1429\n",
            "Epoch 112/250\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.1648 - accuracy: 1.0000 - val_loss: 4.1340 - val_accuracy: 0.1429\n",
            "Epoch 113/250\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.1625 - accuracy: 1.0000 - val_loss: 4.1457 - val_accuracy: 0.1429\n",
            "Epoch 114/250\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.1652 - accuracy: 1.0000 - val_loss: 4.1461 - val_accuracy: 0.1429\n",
            "Epoch 115/250\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.1233 - accuracy: 1.0000 - val_loss: 4.1487 - val_accuracy: 0.1429\n",
            "Epoch 116/250\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.1562 - accuracy: 1.0000 - val_loss: 4.1527 - val_accuracy: 0.1429\n",
            "Epoch 117/250\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.1366 - accuracy: 1.0000 - val_loss: 4.1857 - val_accuracy: 0.1429\n",
            "Epoch 118/250\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 0.1486 - accuracy: 1.0000 - val_loss: 4.2185 - val_accuracy: 0.1429\n",
            "Epoch 119/250\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.1284 - accuracy: 1.0000 - val_loss: 4.2475 - val_accuracy: 0.1429\n",
            "Epoch 120/250\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.1382 - accuracy: 1.0000 - val_loss: 4.2600 - val_accuracy: 0.1429\n",
            "Epoch 121/250\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.1378 - accuracy: 1.0000 - val_loss: 4.2789 - val_accuracy: 0.1429\n",
            "Epoch 122/250\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 0.1286 - accuracy: 0.9744 - val_loss: 4.2819 - val_accuracy: 0.1429\n",
            "Epoch 123/250\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.1375 - accuracy: 1.0000 - val_loss: 4.2863 - val_accuracy: 0.1429\n",
            "Epoch 124/250\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.1752 - accuracy: 1.0000 - val_loss: 4.3203 - val_accuracy: 0.1429\n",
            "Epoch 125/250\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 0.0945 - accuracy: 1.0000 - val_loss: 4.3299 - val_accuracy: 0.1429\n",
            "Epoch 126/250\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.1203 - accuracy: 1.0000 - val_loss: 4.3401 - val_accuracy: 0.1429\n",
            "Epoch 127/250\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 0.1465 - accuracy: 1.0000 - val_loss: 4.3322 - val_accuracy: 0.1429\n",
            "Epoch 128/250\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 0.1268 - accuracy: 0.9872 - val_loss: 4.3222 - val_accuracy: 0.1429\n",
            "Epoch 129/250\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.1158 - accuracy: 1.0000 - val_loss: 4.3367 - val_accuracy: 0.1429\n",
            "Epoch 130/250\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 0.1455 - accuracy: 1.0000 - val_loss: 4.3491 - val_accuracy: 0.1429\n",
            "Epoch 131/250\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 0.1498 - accuracy: 0.9872 - val_loss: 4.3544 - val_accuracy: 0.1429\n",
            "Epoch 132/250\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 0.1498 - accuracy: 1.0000 - val_loss: 4.3051 - val_accuracy: 0.1429\n",
            "Epoch 133/250\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.1517 - accuracy: 1.0000 - val_loss: 4.2716 - val_accuracy: 0.1429\n",
            "Epoch 134/250\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 0.1406 - accuracy: 1.0000 - val_loss: 4.2705 - val_accuracy: 0.1429\n",
            "Epoch 135/250\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.1138 - accuracy: 0.9872 - val_loss: 4.2965 - val_accuracy: 0.1429\n",
            "Epoch 136/250\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.1029 - accuracy: 1.0000 - val_loss: 4.3245 - val_accuracy: 0.1429\n",
            "Epoch 137/250\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 0.1517 - accuracy: 0.9872 - val_loss: 4.3570 - val_accuracy: 0.1429\n",
            "Epoch 138/250\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.1348 - accuracy: 1.0000 - val_loss: 4.3695 - val_accuracy: 0.1429\n",
            "Epoch 139/250\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.1247 - accuracy: 1.0000 - val_loss: 4.3796 - val_accuracy: 0.1429\n",
            "Epoch 140/250\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 0.1230 - accuracy: 1.0000 - val_loss: 4.3862 - val_accuracy: 0.1429\n",
            "Epoch 141/250\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 0.1180 - accuracy: 0.9872 - val_loss: 4.4035 - val_accuracy: 0.1429\n",
            "Epoch 142/250\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.1434 - accuracy: 1.0000 - val_loss: 4.4511 - val_accuracy: 0.1429\n",
            "Epoch 143/250\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.0857 - accuracy: 1.0000 - val_loss: 4.4649 - val_accuracy: 0.1429\n",
            "Epoch 144/250\n",
            "3/3 [==============================] - 0s 59ms/step - loss: 0.1284 - accuracy: 1.0000 - val_loss: 4.4754 - val_accuracy: 0.1429\n",
            "Epoch 145/250\n",
            "3/3 [==============================] - 0s 58ms/step - loss: 0.1127 - accuracy: 1.0000 - val_loss: 4.4782 - val_accuracy: 0.1429\n",
            "Epoch 146/250\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.1094 - accuracy: 1.0000 - val_loss: 4.4894 - val_accuracy: 0.1429\n",
            "Epoch 147/250\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 0.1450 - accuracy: 0.9872 - val_loss: 4.5178 - val_accuracy: 0.1429\n",
            "Epoch 148/250\n",
            "3/3 [==============================] - 0s 48ms/step - loss: 0.1172 - accuracy: 1.0000 - val_loss: 4.5253 - val_accuracy: 0.1429\n",
            "Epoch 149/250\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 0.1395 - accuracy: 0.9872 - val_loss: 4.5159 - val_accuracy: 0.1429\n",
            "Epoch 150/250\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 0.1161 - accuracy: 0.9872 - val_loss: 4.4933 - val_accuracy: 0.1429\n",
            "Epoch 151/250\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 0.0932 - accuracy: 1.0000 - val_loss: 4.4664 - val_accuracy: 0.1429\n",
            "Epoch 152/250\n",
            "3/3 [==============================] - 0s 87ms/step - loss: 0.1186 - accuracy: 1.0000 - val_loss: 4.4536 - val_accuracy: 0.1429\n",
            "Epoch 153/250\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 0.1076 - accuracy: 0.9872 - val_loss: 4.4581 - val_accuracy: 0.1429\n",
            "Epoch 154/250\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 0.1039 - accuracy: 1.0000 - val_loss: 4.4693 - val_accuracy: 0.1429\n",
            "Epoch 155/250\n",
            "3/3 [==============================] - 0s 58ms/step - loss: 0.0941 - accuracy: 0.9872 - val_loss: 4.4802 - val_accuracy: 0.1429\n",
            "Epoch 156/250\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0965 - accuracy: 1.0000 - val_loss: 4.4936 - val_accuracy: 0.1429\n",
            "Epoch 157/250\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.1077 - accuracy: 0.9872 - val_loss: 4.5119 - val_accuracy: 0.1429\n",
            "Epoch 158/250\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0934 - accuracy: 1.0000 - val_loss: 4.5304 - val_accuracy: 0.1429\n",
            "Epoch 159/250\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0910 - accuracy: 1.0000 - val_loss: 4.5408 - val_accuracy: 0.1429\n",
            "Epoch 160/250\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.1063 - accuracy: 1.0000 - val_loss: 4.5446 - val_accuracy: 0.1429\n",
            "Epoch 161/250\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.1186 - accuracy: 1.0000 - val_loss: 4.5378 - val_accuracy: 0.1429\n",
            "Epoch 162/250\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.1026 - accuracy: 1.0000 - val_loss: 4.5316 - val_accuracy: 0.1429\n",
            "Epoch 163/250\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0900 - accuracy: 1.0000 - val_loss: 4.5319 - val_accuracy: 0.1429\n",
            "Epoch 164/250\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.1010 - accuracy: 1.0000 - val_loss: 4.5270 - val_accuracy: 0.1429\n",
            "Epoch 165/250\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0872 - accuracy: 1.0000 - val_loss: 4.5272 - val_accuracy: 0.1429\n",
            "Epoch 166/250\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0933 - accuracy: 1.0000 - val_loss: 4.5460 - val_accuracy: 0.1429\n",
            "Epoch 167/250\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.1076 - accuracy: 1.0000 - val_loss: 4.5710 - val_accuracy: 0.1429\n",
            "Epoch 168/250\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0930 - accuracy: 1.0000 - val_loss: 4.5766 - val_accuracy: 0.1429\n",
            "Epoch 169/250\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.1046 - accuracy: 1.0000 - val_loss: 4.5831 - val_accuracy: 0.1429\n",
            "Epoch 170/250\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.1118 - accuracy: 0.9872 - val_loss: 4.6087 - val_accuracy: 0.1429\n",
            "Epoch 171/250\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0786 - accuracy: 0.9872 - val_loss: 4.6266 - val_accuracy: 0.1429\n",
            "Epoch 172/250\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.0899 - accuracy: 1.0000 - val_loss: 4.6381 - val_accuracy: 0.1429\n",
            "Epoch 173/250\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.0908 - accuracy: 1.0000 - val_loss: 4.6412 - val_accuracy: 0.1429\n",
            "Epoch 174/250\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0821 - accuracy: 1.0000 - val_loss: 4.6504 - val_accuracy: 0.1429\n",
            "Epoch 175/250\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.1118 - accuracy: 1.0000 - val_loss: 4.6713 - val_accuracy: 0.1429\n",
            "Epoch 176/250\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.1056 - accuracy: 0.9872 - val_loss: 4.6847 - val_accuracy: 0.1429\n",
            "Epoch 177/250\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0784 - accuracy: 1.0000 - val_loss: 4.7030 - val_accuracy: 0.1429\n",
            "Epoch 178/250\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0891 - accuracy: 1.0000 - val_loss: 4.7180 - val_accuracy: 0.1429\n",
            "Epoch 179/250\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.0940 - accuracy: 1.0000 - val_loss: 4.7273 - val_accuracy: 0.1429\n",
            "Epoch 180/250\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0748 - accuracy: 1.0000 - val_loss: 4.7530 - val_accuracy: 0.1429\n",
            "Epoch 181/250\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.1114 - accuracy: 1.0000 - val_loss: 4.7812 - val_accuracy: 0.1429\n",
            "Epoch 182/250\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0898 - accuracy: 1.0000 - val_loss: 4.7961 - val_accuracy: 0.1429\n",
            "Epoch 183/250\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.1112 - accuracy: 0.9872 - val_loss: 4.8229 - val_accuracy: 0.1429\n",
            "Epoch 184/250\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0777 - accuracy: 0.9872 - val_loss: 4.8259 - val_accuracy: 0.1429\n",
            "Epoch 185/250\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0900 - accuracy: 1.0000 - val_loss: 4.8234 - val_accuracy: 0.1429\n",
            "Epoch 186/250\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0766 - accuracy: 1.0000 - val_loss: 4.8291 - val_accuracy: 0.1429\n",
            "Epoch 187/250\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0782 - accuracy: 1.0000 - val_loss: 4.8449 - val_accuracy: 0.1429\n",
            "Epoch 188/250\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0834 - accuracy: 1.0000 - val_loss: 4.8596 - val_accuracy: 0.1429\n",
            "Epoch 189/250\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0724 - accuracy: 1.0000 - val_loss: 4.8652 - val_accuracy: 0.1429\n",
            "Epoch 190/250\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.0936 - accuracy: 1.0000 - val_loss: 4.8908 - val_accuracy: 0.1429\n",
            "Epoch 191/250\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0710 - accuracy: 1.0000 - val_loss: 4.9108 - val_accuracy: 0.1429\n",
            "Epoch 192/250\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0524 - accuracy: 1.0000 - val_loss: 4.9213 - val_accuracy: 0.1429\n",
            "Epoch 193/250\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.1000 - accuracy: 1.0000 - val_loss: 4.9263 - val_accuracy: 0.1429\n",
            "Epoch 194/250\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0718 - accuracy: 1.0000 - val_loss: 4.9226 - val_accuracy: 0.1429\n",
            "Epoch 195/250\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0830 - accuracy: 1.0000 - val_loss: 4.9316 - val_accuracy: 0.1429\n",
            "Epoch 196/250\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0833 - accuracy: 1.0000 - val_loss: 4.9360 - val_accuracy: 0.1429\n",
            "Epoch 197/250\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.0912 - accuracy: 1.0000 - val_loss: 4.9441 - val_accuracy: 0.1429\n",
            "Epoch 198/250\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0687 - accuracy: 1.0000 - val_loss: 4.9423 - val_accuracy: 0.1429\n",
            "Epoch 199/250\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0732 - accuracy: 0.9872 - val_loss: 4.9444 - val_accuracy: 0.1429\n",
            "Epoch 200/250\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0901 - accuracy: 1.0000 - val_loss: 4.9517 - val_accuracy: 0.1429\n",
            "Epoch 201/250\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.0968 - accuracy: 1.0000 - val_loss: 4.9505 - val_accuracy: 0.1429\n",
            "Epoch 202/250\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0915 - accuracy: 1.0000 - val_loss: 4.9461 - val_accuracy: 0.1429\n",
            "Epoch 203/250\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.0714 - accuracy: 1.0000 - val_loss: 4.9287 - val_accuracy: 0.1429\n",
            "Epoch 204/250\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0873 - accuracy: 1.0000 - val_loss: 4.9021 - val_accuracy: 0.1429\n",
            "Epoch 205/250\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0862 - accuracy: 1.0000 - val_loss: 4.8805 - val_accuracy: 0.1429\n",
            "Epoch 206/250\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0801 - accuracy: 1.0000 - val_loss: 4.8632 - val_accuracy: 0.1429\n",
            "Epoch 207/250\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.0564 - accuracy: 1.0000 - val_loss: 4.8441 - val_accuracy: 0.1429\n",
            "Epoch 208/250\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.0686 - accuracy: 1.0000 - val_loss: 4.8506 - val_accuracy: 0.1429\n",
            "Epoch 209/250\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0910 - accuracy: 1.0000 - val_loss: 4.8543 - val_accuracy: 0.1429\n",
            "Epoch 210/250\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0871 - accuracy: 1.0000 - val_loss: 4.8754 - val_accuracy: 0.1429\n",
            "Epoch 211/250\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0672 - accuracy: 1.0000 - val_loss: 4.8957 - val_accuracy: 0.1429\n",
            "Epoch 212/250\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0712 - accuracy: 1.0000 - val_loss: 4.9229 - val_accuracy: 0.1429\n",
            "Epoch 213/250\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0602 - accuracy: 1.0000 - val_loss: 4.9487 - val_accuracy: 0.1429\n",
            "Epoch 214/250\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0938 - accuracy: 1.0000 - val_loss: 4.9705 - val_accuracy: 0.1429\n",
            "Epoch 215/250\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0630 - accuracy: 1.0000 - val_loss: 4.9625 - val_accuracy: 0.1429\n",
            "Epoch 216/250\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0581 - accuracy: 1.0000 - val_loss: 4.9655 - val_accuracy: 0.1429\n",
            "Epoch 217/250\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0906 - accuracy: 1.0000 - val_loss: 4.9712 - val_accuracy: 0.1429\n",
            "Epoch 218/250\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0987 - accuracy: 1.0000 - val_loss: 4.9813 - val_accuracy: 0.1429\n",
            "Epoch 219/250\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0588 - accuracy: 1.0000 - val_loss: 4.9877 - val_accuracy: 0.1429\n",
            "Epoch 220/250\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0673 - accuracy: 1.0000 - val_loss: 5.0004 - val_accuracy: 0.1429\n",
            "Epoch 221/250\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0751 - accuracy: 1.0000 - val_loss: 5.0198 - val_accuracy: 0.1429\n",
            "Epoch 222/250\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.0744 - accuracy: 1.0000 - val_loss: 5.0472 - val_accuracy: 0.1429\n",
            "Epoch 223/250\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.0641 - accuracy: 1.0000 - val_loss: 5.0778 - val_accuracy: 0.1429\n",
            "Epoch 224/250\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0773 - accuracy: 1.0000 - val_loss: 5.0793 - val_accuracy: 0.1429\n",
            "Epoch 225/250\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0691 - accuracy: 1.0000 - val_loss: 5.0730 - val_accuracy: 0.1429\n",
            "Epoch 226/250\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.0589 - accuracy: 1.0000 - val_loss: 5.0996 - val_accuracy: 0.1429\n",
            "Epoch 227/250\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0772 - accuracy: 1.0000 - val_loss: 5.1358 - val_accuracy: 0.1429\n",
            "Epoch 228/250\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.0721 - accuracy: 1.0000 - val_loss: 5.1618 - val_accuracy: 0.1429\n",
            "Epoch 229/250\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.0711 - accuracy: 1.0000 - val_loss: 5.1797 - val_accuracy: 0.1429\n",
            "Epoch 230/250\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0568 - accuracy: 1.0000 - val_loss: 5.1822 - val_accuracy: 0.1429\n",
            "Epoch 231/250\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0689 - accuracy: 1.0000 - val_loss: 5.1886 - val_accuracy: 0.1429\n",
            "Epoch 232/250\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0669 - accuracy: 1.0000 - val_loss: 5.1774 - val_accuracy: 0.1429\n",
            "Epoch 233/250\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0483 - accuracy: 1.0000 - val_loss: 5.1667 - val_accuracy: 0.1429\n",
            "Epoch 234/250\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0708 - accuracy: 1.0000 - val_loss: 5.1822 - val_accuracy: 0.1429\n",
            "Epoch 235/250\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0647 - accuracy: 1.0000 - val_loss: 5.1819 - val_accuracy: 0.1429\n",
            "Epoch 236/250\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0781 - accuracy: 1.0000 - val_loss: 5.1789 - val_accuracy: 0.1429\n",
            "Epoch 237/250\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0875 - accuracy: 1.0000 - val_loss: 5.1772 - val_accuracy: 0.1429\n",
            "Epoch 238/250\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0586 - accuracy: 1.0000 - val_loss: 5.1825 - val_accuracy: 0.1429\n",
            "Epoch 239/250\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0552 - accuracy: 1.0000 - val_loss: 5.1885 - val_accuracy: 0.1429\n",
            "Epoch 240/250\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0488 - accuracy: 1.0000 - val_loss: 5.1771 - val_accuracy: 0.1429\n",
            "Epoch 241/250\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0551 - accuracy: 1.0000 - val_loss: 5.1777 - val_accuracy: 0.1429\n",
            "Epoch 242/250\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0901 - accuracy: 0.9872 - val_loss: 5.1793 - val_accuracy: 0.1429\n",
            "Epoch 243/250\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0602 - accuracy: 1.0000 - val_loss: 5.2077 - val_accuracy: 0.1429\n",
            "Epoch 244/250\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0624 - accuracy: 1.0000 - val_loss: 5.2289 - val_accuracy: 0.1429\n",
            "Epoch 245/250\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0619 - accuracy: 1.0000 - val_loss: 5.2411 - val_accuracy: 0.1429\n",
            "Epoch 246/250\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0625 - accuracy: 0.9872 - val_loss: 5.2419 - val_accuracy: 0.1429\n",
            "Epoch 247/250\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0832 - accuracy: 1.0000 - val_loss: 5.2272 - val_accuracy: 0.1429\n",
            "Epoch 248/250\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0595 - accuracy: 1.0000 - val_loss: 5.2181 - val_accuracy: 0.1429\n",
            "Epoch 249/250\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0522 - accuracy: 1.0000 - val_loss: 5.2014 - val_accuracy: 0.1429\n",
            "Epoch 250/250\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0516 - accuracy: 1.0000 - val_loss: 5.1789 - val_accuracy: 0.1429\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7edaf1bb0ca0>"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "classifier_model.fit(x_train,y_train,epochs=250,validation_data=(x_test,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "5BtgAfSo8XW1"
      },
      "outputs": [],
      "source": [
        "# Save model for later use\n",
        "tf.keras.models.save_model(classifier_model,'/content/drive/My Drive/Colab Notebooks/Face_Recognition/face_classifier_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "3c-QvTzD_Xmf"
      },
      "outputs": [],
      "source": [
        "# Load saved model\n",
        "classifier_model=tf.keras.models.load_model('/content/drive/My Drive/Colab Notebooks/Face_Recognition/face_classifier_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "I6_DyNnVAHuM"
      },
      "outputs": [],
      "source": [
        "# Path to folder which contains images to be tested and predicted\n",
        "test_images_path=path+'/Test_Images/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "3aYRHru9AtfM"
      },
      "outputs": [],
      "source": [
        "dnnFaceDetector=dlib.cnn_face_detection_model_v1(\"mmod_human_face_detector.dat\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "AJZg7e93Cgu1"
      },
      "outputs": [],
      "source": [
        "def plot(img):\n",
        "  plt.figure(figsize=(8,4))\n",
        "  plt.imshow(img[:,:,::-1])\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "Sq5OIqWFfmpa"
      },
      "outputs": [],
      "source": [
        "from zmq.sugar import frame\n",
        "video_path = \"/content/drive/MyDrive/videos/Natu_Natu.mp4\"\n",
        "output_path = \"/content/drive/MyDrive/Colab Notebooks/Face_Recognition/Test_Images\"\n",
        "\n",
        "\n",
        "vidcap = cv2.VideoCapture(video_path)\n",
        "success, image = vidcap.read()\n",
        "count = 0\n",
        "frameNum =0\n",
        "while success:\n",
        "    if count % 1000 == 0:\n",
        "        cv2.imwrite(output_path + \"/frame%d.jpg\" %frameNum , image)\n",
        "        frameNum += 1\n",
        "    success, image = vidcap.read()\n",
        "    count += 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wofuBLTOH7Iu"
      },
      "outputs": [],
      "source": [
        "# Label names for class numbers\n",
        "# person_rep={0: 'Ranjith', 1: 'Shiva', 2: 'saiCharanTeja',3:\"None\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "0M57Q7chO_Xc"
      },
      "outputs": [],
      "source": [
        "if(os.path.exists(path+'/Predictions')==False):\n",
        "    os.mkdir(path+'/Predictions')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if(os.path.exists(path+'/Test_Images_crop/') == False):\n",
        "    os.mkdir(path+'/Test_Images_crop/')"
      ],
      "metadata": {
        "id": "e2ZCzmDrQObU"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "EZPML3AAVw60"
      },
      "outputs": [],
      "source": [
        "# Function to predict faces in a name and update the frequency dictionary\n",
        "\n",
        "def process_name(img_name, frequency_dict):\n",
        "  try:\n",
        "    img=cv2.imread(path+'/Test_Images/'+img_name)\n",
        "    gray=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    # Detect Faces\n",
        "    rects=dnnFaceDetector(gray,1)\n",
        "    left,top,right,bottom=0,0,0,0\n",
        "\n",
        "    for (i,rect) in enumerate(rects):\n",
        "        # Extract Each Face\n",
        "        left=rect.rect.left() #x1\n",
        "        top=rect.rect.top() #y1\n",
        "        right=rect.rect.right() #x2\n",
        "        bottom=rect.rect.bottom() #y2\n",
        "        width=right-left\n",
        "        height=bottom-top\n",
        "        img_crop=img[abs(top):abs(top)+height,abs(left):abs(left)+width]\n",
        "        cv2.imwrite(path+'/Test_Images_crop/'+img_name[:-5]+\"Crop_img.jpg\",img_crop)\n",
        "        # Get Embeddings\n",
        "        crop_img=cv2.imread(path+'/Test_Images_crop/'+img_name[:-5]+\"Crop_img.jpg\")\n",
        "\n",
        "        crop_img= cv2.resize(crop_img,(224,224))\n",
        "\n",
        "        crop_img=img_to_array(crop_img)\n",
        "        crop_img=np.expand_dims(crop_img,axis=0)\n",
        "        crop_img=preprocess_input(crop_img)\n",
        "        img_encode=vgg_face(crop_img)\n",
        "\n",
        "\n",
        "        # Make Predictions\n",
        "        embed=K.eval(img_encode)\n",
        "        person=classifier_model.predict(embed)\n",
        "        name=person_rep[np.argmax(person)]\n",
        "\n",
        "        os.remove(path+'/Test_Images_crop/'+img_name[:-5]+\"Crop_img.jpg\")\n",
        "\n",
        "        cv2.rectangle(img,(abs(left),abs(top)),(right,bottom),(0,255,0), 2)\n",
        "\n",
        "        if(np.max(person)>0.75):\n",
        "            img=cv2.putText(img,name,(abs(left),abs(top)-10),cv2.FONT_HERSHEY_SIMPLEX,2,(255,0,255),2,cv2.LINE_AA)\n",
        "            img=cv2.putText(img,str(np.max(person)),(right,bottom+10),cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,255),1,cv2.LINE_AA)\n",
        "            # Update the frequency dictionary\n",
        "            frequency_dict[name] +=1\n",
        "\n",
        "    # Save images with bounding box,name and accuracy\n",
        "    cv2.imwrite(path+'/Predictions/'+img_name,img)\n",
        "\n",
        "  except:\n",
        "    pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPoSEcE9Ws-K",
        "outputId": "895d80a0-d8c6-48cb-ae08-8c6cea54c002"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 6s 6s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 6s 6s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 0s 433ms/step\n",
            "1/1 [==============================] - 0s 470ms/step\n",
            "1/1 [==============================] - 1s 535ms/step\n",
            "1/1 [==============================] - 1s 613ms/step\n",
            "1/1 [==============================] - 1s 589ms/step\n",
            "1/1 [==============================] - 0s 428ms/step\n",
            "1/1 [==============================] - 0s 439ms/step\n",
            "1/1 [==============================] - 0s 406ms/step\n",
            "1/1 [==============================] - 1s 676ms/step\n",
            "1/1 [==============================] - 0s 166ms/step\n",
            "1/1 [==============================] - 0s 113ms/step\n",
            "1/1 [==============================] - 0s 181ms/step\n",
            "1/1 [==============================] - 0s 131ms/step\n",
            "1/1 [==============================] - 0s 128ms/step\n",
            "1/1 [==============================] - 0s 157ms/step\n",
            "1/1 [==============================] - 0s 222ms/step\n",
            "1/1 [==============================] - 0s 209ms/step\n",
            "1/1 [==============================] - 0s 221ms/step\n",
            "1/1 [==============================] - 0s 140ms/step\n",
            "1/1 [==============================] - 0s 206ms/step\n",
            "1/1 [==============================] - 0s 171ms/step\n",
            "1/1 [==============================] - 0s 283ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 110ms/step\n",
            "1/1 [==============================] - 0s 110ms/step\n",
            "1/1 [==============================] - 0s 162ms/step\n",
            "1/1 [==============================] - 0s 91ms/step\n",
            "1/1 [==============================] - 0s 93ms/step\n",
            "1/1 [==============================] - 0s 138ms/step\n",
            "1/1 [==============================] - 0s 76ms/step\n",
            "1/1 [==============================] - 0s 74ms/step\n",
            "1/1 [==============================] - 0s 100ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 81ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "Name: MalliReddy, Frequency: 7\n",
            "Name: Pragna, Frequency: 0\n",
            "Name: RamCharanTeja, Frequency: 10\n",
            "Name: Ranjith, Frequency: 0\n",
            "Name: NTR, Frequency: 2\n",
            "Name: Shiva, Frequency: 5\n",
            "Name: saiCharanTeja, Frequency: 12\n",
            "Name: Pragna (), Frequency: 4\n"
          ]
        }
      ],
      "source": [
        "# List of names to process\n",
        "names = list(person_names)\n",
        "\n",
        "# Dictionary to store the frequency of faces in each name\n",
        "frequency_dict = defaultdict(int)\n",
        "\n",
        "for i in names:\n",
        "    frequency_dict[i] =0\n",
        "\n",
        "# Create a lock to synchronize access to the dictionary\n",
        "lock = threading.Lock()\n",
        "\n",
        "# Create threads to process each name\n",
        "threads = []\n",
        "\n",
        "\n",
        "for img_name in os.listdir('Test_Images/'):\n",
        "    t = threading.Thread(target=process_name, args=(img_name, frequency_dict))\n",
        "    threads.append(t)\n",
        "    t.start()\n",
        "\n",
        "\n",
        "# Wait for all threads to finish\n",
        "for t in threads:\n",
        "    t.join()\n",
        "\n",
        "# Print the frequencies of faces in each name\n",
        "for name, frequency in frequency_dict.items():\n",
        "    print(f\"Name: {name}, Frequency: {frequency}\")\n",
        "attendance = frequency_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "CTjekZAghds1"
      },
      "outputs": [],
      "source": [
        "class Student:\n",
        "    def __init__(self, name, MobileNumber,Mail):\n",
        "        self.name = name\n",
        "        self.MobileNumber = MobileNumber\n",
        "        self.Mail = Mail"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y6zJQMwll4LZ"
      },
      "outputs": [],
      "source": [
        "#load Student Info details\n",
        "df = pd.read_excel(path+'/Students_Info.xlsx',index_col=0);\n",
        "students_Info =[]\n",
        "for idx in df.index:\n",
        "    students_Info.append(Student(df[\"Name\"][idx],df[\"Mobile_Number\"][idx],df[\"Mail_Id\"][idx]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nkX6I1A3Lyay"
      },
      "outputs": [],
      "source": [
        "for i in students_Info:\n",
        "    print(i.name,i.MobileNumber,i.Mail)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "597JXz4CswuN"
      },
      "outputs": [],
      "source": [
        "if(os.path.exists(path+'/StudentAttendance/')== False):\n",
        "    os.mkdir(path+'/StudentAttendance/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LSiyY2DNsudj"
      },
      "outputs": [],
      "source": [
        "# datetime object containing current date and time\n",
        "now = datetime.now()\n",
        "\n",
        "# dd/mm/YY H:M:S\n",
        "dt_string = now.strftime(\"D_%d_%m_%Y_T_%H_%M_%S.xlsx\")\n",
        "\n",
        "dict_ ={\"Name\":attendance.keys(),\"Attentiveness\":attendance.values()}\n",
        "\n",
        "df = pd.DataFrame(dict_)\n",
        "df.to_excel(path+'/StudentAttendance/'+dt_string)\n",
        "df = pd.read_excel(path+'/StudentAttendance/'+dt_string,index_col=0)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZO_XIQVoupvW"
      },
      "outputs": [],
      "source": [
        "def SendMessage(message,mobileNumber):\n",
        "    account_sid = \"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\"\n",
        "    auth_token = \"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\"\n",
        "\n",
        "    client = Client(account_sid, auth_token)\n",
        "    message = client.messages.create(\n",
        "    body=message,\n",
        "    from_=\"whatsapp:+XXXXXXXX\",\n",
        "    to=\"whatsapp:+\"+str(mobileNumber)\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1vO1D_RvIRO"
      },
      "outputs": [],
      "source": [
        "for i in students_Info:\n",
        "    attentiveness = 0\n",
        "    if(i.name in attendance.keys()):\n",
        "        attentiveness = attendance[i.name]\n",
        "\n",
        "    print(\"Message Successfully sent to :\" +i.name)\n",
        "    msg =\"Hello : \"+i.name+ \",\\n Your attentiveness Percentage is \"+str(attentiveness)+\" %\"\n",
        "    if(attentiveness <50):\n",
        "         msg = msg + \"\\n Make sure to Focus on the class Next time.\"\n",
        "         msg = msg + \".\\nAnd You are Absent for the class Today\\n\"\n",
        "    else:\n",
        "         msg = msg + \". \\nAnd You are Present for the class Today.\\n\"\n",
        "    msg+=\"Regards JNTUHCES BATCH 7\"\n",
        "    SendMessage(msg,i.MobileNumber)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HA1139EXFT06"
      },
      "outputs": [],
      "source": [
        "outlook.username = \"XXXXXXX@outlook.com\"\n",
        "outlook.password = \"XXXXXXXX\"\n",
        "\n",
        "def sendmail(candidate_email,attentive,attentiveness):\n",
        "    status = \"PRESENT\"\n",
        "    header = \"This is \"\n",
        "    footer =\"Your active participation and attentiveness were commendable, and we appreciate your dedication to the class.</p><p>Keep up the excellent work!</p>\"\n",
        "    if attentive == False:\n",
        "        status = \"ABSENT\"\n",
        "        header = 'We regret '\n",
        "        footer =\" We kindly request that you make a conscious effort to be more attentive during future classes.</p><p>Keep up the excellent work!</p>\"\n",
        "\n",
        "    message = '''\n",
        "        <!DOCTYPE html>\n",
        "<head>\n",
        "<style>\n",
        "    body {\n",
        "        background-image: url('https://jntuh.ac.in/images/jntuhlogo.png');\n",
        "        background-size: cover;\n",
        "        background-repeat: no-repeat;\n",
        "        background-color: rgba(20, 136, 234, 0.2);\n",
        "        opacity:1;\n",
        "        z-index: -1;\n",
        "    }\n",
        "\n",
        "    #card {\n",
        "        position: relative;\n",
        "        top:60px;\n",
        "        width: 320px;\n",
        "        display: block;\n",
        "        margin: auto;\n",
        "        text-align: center;\n",
        "        font-family: 'Source Sans Pro', sans-serif;\n",
        "        border: 6px solid  #0000FF;\n",
        "        border-radius: 10px;\n",
        "\n",
        "\n",
        "    }\n",
        "\n",
        "    #upper-side {\n",
        "        padding: 2em;\n",
        "        background-color: rgba(0, 0, 255, 1);\n",
        "        display: block;\n",
        "        color: #fff;\n",
        "\n",
        "        border-bottom-right-radius: 10px;\n",
        "        border-bottom-left-radius: 10px;\n",
        "\n",
        "    }\n",
        "\n",
        "\n",
        "    #status {\n",
        "        font-weight: lighter;\n",
        "        text-transform: uppercase;\n",
        "        letter-spacing: 5px;\n",
        "        font-size: 1em;\n",
        "        margin-top: -0.2em;\n",
        "        margin-bottom: 0;\n",
        "    }\n",
        "\n",
        "    #lower-side {\n",
        "        padding: 2em 2em 5em 2em;\n",
        "        background: #fff;\n",
        "        display: block;\n",
        "        border-bottom-right-radius: 10px;\n",
        "        border-bottom-left-radius: 10px;\n",
        "    }\n",
        "\n",
        "    #message {\n",
        "        margin-top: -0.5em;\n",
        "        color: #757575;\n",
        "        letter-spacing: 1px;\n",
        "        color: #000000;\n",
        "  \t\tfont-size: 16px;\n",
        "  \t\tfont-weight: bold;\n",
        "  \t\tfont-style: normal;\n",
        "\n",
        "    }\n",
        ".envelope-header {\n",
        "      margin-bottom: 30px;\n",
        "       text-align: center;\n",
        "    }\n",
        "\n",
        "</style>\n",
        "\n",
        "</head>\n",
        "\n",
        "<html>\n",
        "<body>\n",
        "<div class=\"envelope-header\">\n",
        "      <img src=\"https://jntuh.ac.in/images/jntuhlogo.png\" alt=\"Attendance\">\n",
        "    </div>\n",
        "<div id=\"card\" class=\"animated fadeIn\">\n",
        "\n",
        "    <div id=\"upper-side\">\n",
        "        <h1 id=\"status\"><b>Attendance Status</b></h1>\n",
        "    </div>\n",
        "    <div id=\"lower-side\">\n",
        "        <p id=\"message\">'''+ header +'''to inform you that you were marked <h3> <b style=\"color: #FF0000;\">'''+ status+''' </b> </h3>\n",
        "        </p>\n",
        "        <p id=\"message\">'''+footer+'''\n",
        "        <p style=\"color: #006400;font-weight: bold; \"><b>And Your percentage of Attentativeness is</b>\n",
        "        \t<h1>\n",
        "              \t<b style=\"color: #00FF00;\">'''+ str(attentiveness) +'''%\n",
        "            \t<b>\n",
        "             </h1>\n",
        "        </p>\n",
        "  \t</div>\n",
        "</div>\n",
        "\n",
        "</body>\n",
        "</html>\n",
        "\n",
        "'''\n",
        "    outlook.send(\n",
        "        receivers=[candidate_email,],\n",
        "        subject=\"Your Attendance @ JNTU\",\n",
        "        html=message\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26VlQ_NwxNCu"
      },
      "outputs": [],
      "source": [
        "#Mailing\n",
        "for i in students_Info:\n",
        "    status = False\n",
        "    attentiveness = 0\n",
        "    if(i.name in attendance.keys()):\n",
        "        if(attendance[i.name] > 50):\n",
        "            status = True\n",
        "        attentiveness = attendance[i.name]\n",
        "    sendmail(i.Mail,status,attentiveness)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l50296guN3kb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iFREBP5tQg-_"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
